{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2167f87e",
   "metadata": {},
   "source": [
    "# TASK 1\n",
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be97cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "testdata = load_data('adult_test.csv')\n",
    "traindata = load_data('adult_train.csv')\n",
    "\n",
    "Ytest = testdata['target']\n",
    "Ytrain = traindata['target']\n",
    "Xtest = testdata.drop('target', axis=1)\n",
    "Xtrain = traindata.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3d8a5",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4bdc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree average cross-validation score: 0.8555020227924419\n",
      "Random Forest average cross-validation score: 0.8467491260155932\n",
      "Gradient Boosting average cross-validation score: 0.8656675592304335\n",
      "Perceptron average cross-validation score: 0.7660086178050249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smelk\\ChalmersCode\\AML (DAT341)\\Applied-Machine-Learning-DAT341-\\sklearn-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\smelk\\ChalmersCode\\AML (DAT341)\\Applied-Machine-Learning-DAT341-\\sklearn-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\smelk\\ChalmersCode\\AML (DAT341)\\Applied-Machine-Learning-DAT341-\\sklearn-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\smelk\\ChalmersCode\\AML (DAT341)\\Applied-Machine-Learning-DAT341-\\sklearn-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\smelk\\ChalmersCode\\AML (DAT341)\\Applied-Machine-Learning-DAT341-\\sklearn-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average cross-validation score: 0.8509260396236444\n",
      "Linear SVC average cross-validation score: 0.8515094975424317\n",
      "MLP Classifier average cross-validation score: 0.8485305093838027\n",
      "Final Test Accuracy: 0.871199557766722\n"
     ]
    }
   ],
   "source": [
    "Xtrain_dict = Xtrain.to_dict('records')\n",
    "Xtest_dict = Xtest.to_dict('records')\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "Xtrain_encoded = dv.fit_transform(Xtrain_dict)\n",
    "Xtest_encoded = dv.transform(Xtest_dict)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=0, max_depth=7)\n",
    "clf2 = RandomForestClassifier(random_state=0)\n",
    "clf3 = GradientBoostingClassifier(random_state=0)\n",
    "clf4 = Perceptron(random_state=0)\n",
    "clf5 = LogisticRegression(random_state=0, max_iter=2000)\n",
    "clf6 = LinearSVC(random_state=0, max_iter=2000)\n",
    "clf7 = MLPClassifier(random_state=0, max_iter=500)\n",
    "\n",
    "classifiers = [clf1, clf2, clf3, clf4, clf5, clf6, clf7]\n",
    "classifier_names = ['Decision Tree', 'Random Forest', 'Gradient Boosting', 'Perceptron',\n",
    "                    'Logistic Regression', 'Linear SVC', 'MLP Classifier']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Used to compare classifiers\n",
    "def compare_classifiers(Xtrain_encoded, Ytrain, classifiers, classifier_names):\n",
    "    for clf, name in zip(classifiers, classifier_names):\n",
    "        crossArray = cross_val_score(clf, Xtrain_encoded, Ytrain)\n",
    "        score = np.mean(crossArray)\n",
    "        print(f'{name} average cross-validation score: {score}')\n",
    "    \n",
    "compare_classifiers(Xtrain_encoded, Ytrain, classifiers, classifier_names)    \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gradient Boosting Classifier selected based on the best cross-validation score\n",
    "clf3.fit(Xtrain_encoded, Ytrain)\n",
    "Yguess = clf3.predict(Xtest_encoded)\n",
    "\n",
    "print(f\"Final Test Accuracy: {accuracy_score(Ytest, Yguess)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1d087",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d0b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy with Pipeline: 0.8699097107057306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "  \n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(), # Convert data to correct format\n",
    "    StandardScaler(with_mean=False), # Scales features to better suit the model\n",
    "    SelectKBest(f_classif, k=50), # Selects the best 50 features based on f_classif\n",
    "    GradientBoostingClassifier() # Our chosen classifier\n",
    ")\n",
    "\n",
    "pipeline.fit(Xtrain_dict, Ytrain)\n",
    "Yguess_pipeline = pipeline.predict(Xtest_dict)\n",
    "print(f\"Final Test Accuracy with Pipeline: {accuracy_score(Ytest, Yguess_pipeline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad9517c",
   "metadata": {},
   "source": [
    "The pipeline did get a bit worse results however this is due to the f_classif evaluator being meant for numerical features but our data does have class based data as well. Seperating what test to use on what feature is possible if we would've used ColumnTransformer instead of DictVectorizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
